# 5주차 수업

clf.fit(X.T, np.squeeze(Y.T)); 

- fit 이라는게 많이 나올예정 (학습)

- 랜덤 이니셜라이제이션 했을때 문제 ?

## 강의 1

- 최적의 노드나 레이어 갯수를 파악해야만 한다.
  - 하이퍼 파라미터를 최적의 값으로 맞추는것
  - 여러번 시도를 해봐야함
  - validation set을 따로 설정한다.
  - n^l : l 번째 layer에 존재하는 node 갯수

### shape이 중요

- n_x 는 feature 갯수
- m 은 데이터 갯수

- w에서 생각
  - 첫번째 레이어라면 ?
    - (n^1, n^0)
  - (그 layer node갯수, 그 전 layer node 갯수)

- b에서 생각
  - (n^l, 1)
  - 그 layer node 갯수.

- tensorflow
  - layer를 하나씩 쌓아서 만듭니다.
  - 각 layer마다 initialization 하는 방법이 다를수 있다.
  - 그리고 initialization 된 대로 forward propagation 진행
  - 그다음 backward propagation
  - 그리고 dw, db 를 계산 후 w,b 를 업데이트 해줍니다.

- gpu 메모리가 중요. (한번에 연산양이 많아짐)

## 강의 2

### 하이퍼 파라미터

- learning rate
- 몇번 학습할까? (Epoch ) : 1Epoch 1번학습 10Epoch 10번학습
- layer 갯수
- node 갯수
- activation

### 하이퍼 파라미터란 무엇인가

- tunning 가능한것
- tune 이라는 단어가 많이 등장
- parameter 는 update 라는 단어가 많이 등장
  - 좀더 자동적인 느낌.
- 하이퍼 파라미터는 조율 해야하는것
  - 수동적으로 최적의 값을 찾아야합니다.


## 하이퍼 파라미터 선택때 주의사항

- learning rate 나 epoch 같은걸 초기값을 설정해뒀다가 여러요소를 한번에 바꿔버리면 파악이 힘듬
- 그래서 바꿀때 하나만 바꿔라
  - learning rate를 바꾸거나 epoch을 바꾸거나
  - 그랬을때 성능이 증가했거나 떨어졌거나를 기록한다.

## C2

- 하이퍼파라미터 탐색과정에 대해 다룸
- 하이퍼파라미터를 효율적으로 탐색하는 방법은
  - Train / dev / test
  - 으로 나눠서 한다.

## 신경망 올바르게 구성

- 훈련할때 생각해야할점
  - Train : 훈련을 위한 데이터
    - 알고리즘 훈련
  - Dev : 검증을 위한 데이터 (validation set)
    - 어떤 모델이 dev 에서 잘 동작하는지
    - 하이퍼 파라미터를 결정하기 위한 데이터
    - 여러번 evaluate (여러번 평가,검증 가능)
    - 학습하지않음 = gradient descent 하지 않음.
  - Test : 
    - 결정된 모델을 테스트
    - 최종적으로 test만 함.
    - 한번만 evaluate
    - 학습 x

- 보통 학습, 검증 두종류로 구분하고 private data 로 test를 진행함.

- 근데 두종류로 하면 validation에 overfit 되어서 unseen data를 하나 더확보해서
- 세종류로 train, dev, test 로 분류하면 좋긴한데 data가 많이 필요함.

- 데이터 set 마다 최적의 하이퍼 파라미터가 다르다.

### distribution

- 만약에 training 을 cat:200, non-cat:200 이면
- validation data 를 cat:50, non-cat:50 처럼 비율을 맞춰주는것도 중요하다.

### Holdout

- 숨겨진카드
- data를 다 쓰지않고 검증을 위해 남겨둔다.

## 강의 3

- bias, variance