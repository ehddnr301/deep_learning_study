# 8주차

## 1

### 7주차 과제 풀이

- 스케일링

  - StandardScaler
    - 인스턴스화
    - fit_transform
  - MinMaxScaler
    - 인스턴스화
    - fit_transform

- Momentum 은 SGD 에서 구현하게 되어있습니다.

### CNN

- 분야와 상관없이 많이 사용됨.
- 활용분야

  - image classification 이미지에 특화
  - object detection 분야에 활용
    - 물체가 어디에 있는지 판단
    - 물체가 무엇인지 분류하는 역할
    - 2가지를 한번에 수행
    - 자율주행에 이용
  - segmentation
    - 영역을 칠하고 해당영역이 어떤것인지
    - object detection 보다 학습 오래걸림
  - Neural Styler Transfer
    - 인공지능으로 화풍을 학습해서 이미지를 재창조
    - 판별이 아니라 새로운것을 생성
    - 생성모델
  - NLP
    - 인접정보를 읽는데 특화된 CNN이기때문에 자연어 처리에도 좋음
    - 인접한 단어 특징을 추출해서 문맥파악이 가능합니다.
  - 알파고 내부구조도 CNN
  - 이미지를 보고 텍스트를 만들어주는 기법도 존재

- 무엇인가 ?

  - 인간이 시각을 처리하는 방법에서 유래
  - 간단한 점, 선들로 부터 뉴런이 반응
    - 선의 모양, 움직임 마다 반응하는 뉴런들이 다릅니다.
  - `특정 feature를 detect 하는 뉴런이 필요`
  - `인접 feature를 detect하는 뉴런이 필요`
  - `feature를 계층적으로 학습할 필요가 있다.`

- 기존 Fully-Connected 를 이미지에 적용했을때
  - 2가지 문제점
    - 대상이 어디에 위치하느냐에 따라 판별될때도 있고 안될때도 있음.
    - 필요한정보만 보지 못하고 다 학습해서 비효율적임.

### Convolution

- input & filter & output 존재
- filter = kernel
- 겹쳐서 element wise product로 convolution 연산

```
0 | 0 | 1 | 0 | 0
0 | 1 | 0 | 1 | 0
1 | 0 | 0 | 0 | 1
0 | 1 | 0 | 1 | 0
0 | 0 | 1 | 0 | 0
```

```
0 | 0 | 1
0 | 1 | 0
1 | 0 | 0
```

```
3 | 0 | 1
0 | 2 | 0
1 | 0 | 3
```

- 결과를 activation map 이라고도 합니다.
- 장점
  - locally-connected
  - 인접한 정보끼리만 연산
  - convolutaion filter는 움직여도 feature를 추출한다.

### RGB는 convolution 어떻게 ?

- filter도 channel 갯수 맞춰주면 결과는 channel이 없는 2d arr
- 이미지적으로 이해하는것도 중요

- convolution 이해
  - 이미지 와 filter 두개의 채널갯수를 맞춰야 합니다.
  - 필터의 갯수는 map 의 갯수가 같다.

## 2

### Convolution layer

- 기존의 Dense layer와 유사
- filter = w 와 유사하다고 생각하면 편함
- encoding 이라고도 부름.

1. input data (= image)
2. filter = kernel = window = fully connected 의 weight
   - filter 모양의 feature 추출
   - filter 갯수가 많을수록 더 다양한 feature 추출
   - 이것도 학습가능
3. activation map = feature map
   - filter가 찾은 특성이 얼마나 있는지 압축해서 표현
   - filter 갯수 = output activation map 의 depth

- convolution layer 의 filter = 기존의 weight
  - Dense 에서는 Node들이 있었는데 feature들의 조합으로 특징추출
  - convolution도 마찬가지. 많으면 많을수록 더 다양한 특징추춝
  - filter의 갯수가 많을수록 overfitting 가능성도 증가

#### hyper parameter

- kernel size = w = filter
  - 홀수를 쓰는것이 기본
  - 대부분 3x3을 사용
    - 왜 3x3이냐 ? 더 적은 parameter 를 사용함.
- filters = kernel의 갯수
  - 자기맘대로 (Dense layer에서 unit갯수와 유사)
  - 많을수록 더 많은 feature 뽑지만 overfitting 위험

#### deep CNN

- 계층적으로 학습

  - 이미지를 보면 edge feature detect
  - edge 들을 모아서 convolution 해서 (조합해서) 더 복잡한 feature

- ex ) 점선 -> 눈코입 -> 얼굴 인식

#### padding

- padding 은 잘 안쓰임
  - 왜? 특징을 압축을 해야하는데 사이즈가 같으면 압축이 안됨.
- 가장자리 부분의 특징을 좀 더 얻는 부수적인 효과
- output size가 줄어드는 것을 막기위해 input data의 외곽을 특정값으로 덧대준다.
- edge 부근의 feature도 잘 추출할 수 있다.
- 일부를 0으로 하니 feature가 일부 희석되서 overfitting 방지

##### hyper parameter

- valid : no padding
- same : padding으로 output size와 input size가 같게끔 만든다.

#### pooling

- 설정한 pool_size 안에서 가장 큰값으로 추출
  - 강한특징이 있냐없냐가 중요한거지 약한특징이 있는지는 중요하지않음
  - 그래서 max_pooling 하면 강한특징만 추출
  - 연산자체를 좀 줄일수 있음.
  - parameter가 있는 layer는 아닙니다.
  - overfitting 방지하는 부수효과.

##### hyper parameter

- 보통 (2,2) 많이씀 혹은 (3,3)
- stride
  - default = pool_size
  - pooling이 3이면 stride는 주로 2를 사용
- padding: valid
- convolution 한번 + maxpooling을 하지만 꼭 그런건 아닙니다.
- conv 2 + maxpool 2 해도 된다

### transfer learning (전이학습)

- 앞쪽부분 학습은 가져와서 다른부분에 붙여도 잘 작동함.

### CNN stride

- `maxpooling 보다는 stride를 쓰는것을 권장!!!`
- convolution이 default로 한칸씩 이동하는데
- 연산이 몇칸씩 이동하며 진행할지 stride로 정해줄수 있습니다.

- overfitting 방지효과
- pooling과 마찬가지로 downsampling 을 목적으로 사용한다.

### shape 계산

- (32,32,3) padding 2 = (36,36,3)
- (5,5) 10개
- (32,32,10) 의 형태의 output

- conv2d의 의 argument (filter갯수, (필터kernelsize))
  - kernel_size는 input이랑 맞춰줘야함.

### Fully-Connected layer

- flatten을 거쳐서 softmax에 넣어줘야함.

## dropout

- dropout 시 모든 kernel 의 pixel값이 아마 0이 될것이다.

## 3

### Matplotlib

- 시각화 하는 라이브러리
- seaborn 같은 다른 라이브러리 를 많이씀

### state machine ??

- 현재 메모리에 올라와있는것에 코드를 추가하면 옵션이 붙음.

### 시각화 하는 원리

- 액자준비(figure) -> 도화지 준비 (axes) -> 그림그려 -> 옵션주고 -> 출력

### 시각화 용어

- Figure : 그림 그 자체 = (액자, 틀)
- Axes :그 안에 그릴 그림 = (실제 그림)

## parameter 갯수 계산

- filter 3x3x3 이 32개
- (32) x (3x3x3+1)

- 18496 = (3x3x32+1) x 64
