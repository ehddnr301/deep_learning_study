# 10

## hyperparameter 관리 기법

- 여러 하이퍼 파라미터를 어떻게 튜닝해야하는지 ?

- 모델을 구성하는 요소가 무엇이 있는지
  - 1. 모델의 껍데기 layer 가 몇개고 node가 몇개고 activation 뭐쓰고
  - 2. 내부의 weight 같은 연산을 하는 값들
  - create_model 함수를 실행하면 껍데기도 얻고 weight도 얻는다 하지만 완전하지 않음
  - 그리고 fit으로 train을 하면 할수록 업데이트 되어감.


## 모델 저장하기

- 파이썬 고유 확장자가 아니라 어떤언어에서도 접근할수있도록 HDF5 사용
- 모델을 저장한다는 어떤 의미 ?
  - model 의 architecture (configure)
  - model 의 weight
  - 위 두개를 한번에 저장.
- 확장자는 h5

## 6주차 ?

- overfitting, underfitting
- overfitting : regularization

## CNN

### ImageDataGenerator

 - 고양이가 좌우반전되거나 회전되도 고양이

## Early stopping

- 에폭에 대한 고민 ( 얼마를 줘서 학습시켜야 할까 ? ) 를 해결해줌.
- patience : 참아주는것 : 감소하다가 가끔 증가하는데 만약에 2로 설정해놓으면 두번 연속 올라가면 학습을 중단.
  - checkpoint 걸어놨으면 그걸 보고 돌아감.?

## Learning late decay

- learning late 가 초반에 속도를 내다가 점차 줄여가는것.
- 초기 러닝레이트보다( 에폭이 증가할수록 ) 러닝레이트를 줄여줌
- 러닝레이트를 코사인 함수모양처럼 빨랐다 느렸다 빨랐다 느렸다 할수도 있음.
  - global optimum 에서는 러닝레이트를 올려도 머물러 있음.

## hyperparameter 튜닝

- 어느정도로 튜닝하면 잘될까 ?
- model
  - layer 수 (1~10 MLP : fully connected) (CNN 은 100~1000)
  - unit 수 = node 수 (10 ~ 1024) = 2의 거듭제곱 : gpu를 좀 병렬처리 하려고.
- optimization
  - underfitting
    - optimizer : 이것저것 다써보기
    - learning rate : 10^-5 ~ 10^-1  보통 0.01 로 많이 시작
  - overfitting
    - dropout : 0.1 - 0.5
    - batch size : 2^5 - 2^10 : 클수록 좋다 training 속도가 빠름 : 크면 학습의 정확도가 높음 : 노이즈가 없음 : 잘 학습이 된다. : 최대한 키우면 좋다.
    - epoch : 길게해서 학습양상을 파악해도 좋을듯.


# 다른팀

##